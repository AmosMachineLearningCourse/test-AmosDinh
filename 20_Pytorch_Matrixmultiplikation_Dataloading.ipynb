{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier werden wir bezüglich Pytorch lernen:\n",
    "- Methoden zum Rechnen mit Matrizen\n",
    "- Indexoperationen auf Matrizen\n",
    "- Data Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Rechnen mit Matrizen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tensoren erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), torch.Size([2, 2]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "A = torch.tensor([[1, 2], [3, 4]])\n",
    "B = torch.tensor([[5, 6], [7, 8]])\n",
    "A.shape, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8403, -0.3911],\n",
       "         [ 0.1047, -0.2206]]),\n",
       " tensor([[0., 0.],\n",
       "         [0., 0.]]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = torch.randn(2, 2)  # Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 (also called the standard normal distribution)\n",
    "C2 = torch.zeros(2, 2)  \n",
    "C1, C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 0]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C3 = torch.zeros_like(A)  # Returns a tensor filled with zeros with the same shape as input\n",
    "C3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[1, 1],\n",
       "         [1, 1]]),\n",
       " torch.float32,\n",
       " torch.int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Einsen\n",
    "C4 = torch.ones(2, 2)  # Returns a tensor filled with ones\n",
    "C5 = torch.ones_like(A)  # Returns a tensor filled with ones with the same shape as input\n",
    "C4, C5, C4.dtype, C5.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Einheitsmatrix\n",
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0],\n",
       "        [0, 2, 0, 0],\n",
       "        [0, 0, 3, 0],\n",
       "        [0, 0, 0, 4]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diagonalmatrix von Vektor\n",
    "D = torch.tensor([1,2,3,4])\n",
    "torch.diag(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(D).diag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Arbeiten mit Dimensionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 3],\n",
       "         [2, 4]]),\n",
       " tensor([[1, 3],\n",
       "         [2, 4]]),\n",
       " tensor([[1, 3],\n",
       "         [2, 4]]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose \n",
    "A.T, torch.t(A), torch.transpose(A, 0, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 4, 7])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.zeros(2,4,5,7)\n",
    "A.transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4]) torch.Size([4])\n",
      "tensor([[1, 2, 3, 4]]) torch.Size([1, 4])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# 0 d vs 1 d\n",
    "print(D, D.shape)\n",
    "# Eine Dimension hinzufügen\n",
    "print(D.unsqueeze(0), D.unsqueeze(0).shape)\n",
    "print(D.unsqueeze(1), D.unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze <-> Unsqueeze rückgängig\n",
    "D1 = D.unsqueeze(0)\n",
    "print(D1.squeeze(0), D1.squeeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "+\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "=\n",
      "tensor([[2., 1., 1., 1.],\n",
      "        [2., 3., 2., 2.],\n",
      "        [3., 3., 4., 3.],\n",
      "        [4., 4., 4., 5.]])\n",
      "In Shapes:\n",
      "torch.Size([4, 1])\n",
      "+\n",
      "torch.Size([4, 4])\n",
      "=\n",
      "torch.Size([4, 4])\n",
      "\n",
      "-> Die 2. Dimension von E wird 'vervielfacht'\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting bei elementweisen Operationen: Addition, Subtraktion, Multiplikation, Division\n",
    "E = D.unsqueeze(1) \n",
    "\n",
    "F = torch.eye(4)\n",
    "print(E)\n",
    "print(\"+\")\n",
    "print(F)\n",
    "print(\"=\")\n",
    "print(E+F)\n",
    "\n",
    "print(\"In Shapes:\")\n",
    "print(E.shape)\n",
    "print('+')\n",
    "print(F.shape)\n",
    "print('=')\n",
    "print((E+F).shape)\n",
    "print(\"\\n-> Die 2. Dimension von E wird 'vervielfacht'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n",
      "+\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "=\n",
      "tensor([[2., 2., 3., 4.],\n",
      "        [1., 3., 3., 4.],\n",
      "        [1., 2., 4., 4.],\n",
      "        [1., 2., 3., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting bei elementweisen Operationen: Addition, Subtraktion, Multiplikation, Division\n",
    "E = D.unsqueeze(0) \n",
    "\n",
    "F = torch.eye(4)\n",
    "print(E)\n",
    "print(\"+\")\n",
    "print(F)\n",
    "print(\"=\")\n",
    "print(E+F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Besser nicht mit 0-Dimensionalen Tensoren arbeiten! (Hier kann man schnell durcheinander kommen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2., 1., 1., 1.],\n",
       "         [1., 2., 1., 1.],\n",
       "         [1., 1., 2., 1.],\n",
       "         [1., 1., 1., 2.]]),\n",
       " tensor([[ 0., -1., -1., -1.],\n",
       "         [-1.,  0., -1., -1.],\n",
       "         [-1., -1.,  0., -1.],\n",
       "         [-1., -1., -1.,  0.]]),\n",
       " tensor([[2.7500, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 2.7500, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 2.7500, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 2.7500]]),\n",
       " tensor([[0.5000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.5000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.5000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.5000]]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mehr Broadcasting Beispiele\n",
    "F + 1, F - 1, F * 2.75, F / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Matrix Multiplikation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[19, 22],\n",
       "         [43, 50]]),\n",
       " tensor([[19, 22],\n",
       "         [43, 50]]),\n",
       " tensor([[19, 22],\n",
       "         [43, 50]]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplikation \n",
    "torch.matmul(A, B), A @ B, torch.mm(A, B),  # .mm nur für 2D Tensoren\n",
    "# nutze .matmul (Klarer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2025-03-02-17-46-53.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 13, 9, 2, 4])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(12,13,9, 2, 3)  \n",
    "B = torch.randn(12,13,9, 3, 4)  \n",
    "C = torch.matmul(A, B)  \n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (9) must match the size of tensor b (10) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \n\u001b[1;32m      2\u001b[0m B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m)  \n\u001b[0;32m----> 3\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m  \n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (9) must match the size of tensor b (10) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "A = torch.randn(12,13,9, 2, 3)  \n",
    "B = torch.randn(12,13,10, 3, 4)  \n",
    "C = torch.matmul(A, B)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 0., 0.],\n",
       "        [0., 8., 0.],\n",
       "        [0., 0., 8.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matrix_power(torch.eye(3)*2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noch viele viele mehr Operationen:\n",
    "# torch.inverse, torch.det, torch.eig, torch.svd,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Aggregatoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(10.),\n",
       " tensor(2.5000),\n",
       " tensor(1.2910),\n",
       " tensor(1.6667),\n",
       " tensor(4.),\n",
       " tensor(1.),\n",
       " tensor(3),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Einige nützliche Funktionen\n",
    "T = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "T.sum(), T.mean(), T.std(), T.var(), T.max(), T.min(), T.argmax(), T.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: tensor([[1., 2., 3.],\n",
      "        [6., 5., 4.],\n",
      "        [7., 8., 9.]])\n",
      "M.sum(): tensor(45.)\n",
      "M.sum(dim=0): tensor([14., 15., 16.])\n",
      "M.sum(dim=1): tensor([ 6., 15., 24.])\n"
     ]
    }
   ],
   "source": [
    "M = torch.tensor([[1,2,3], [6,5,4], [7,8,9]], dtype=torch.float32)\n",
    "print('M:', M)\n",
    "print('M.sum():', M.sum())\n",
    "print('M.sum(dim=0):', M.sum(dim=0))\n",
    "print('M.sum(dim=1):', M.sum(dim=1))\n",
    "\n",
    "# Analog für mean, std, var, max, min, argmax, argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: tensor([[4., 9., 2.],\n",
      "        [3., 5., 7.],\n",
      "        [8., 1., 6.]])\n",
      "M.sum(): tensor(45.)\n",
      "M.sum(dim=0): tensor([15., 15., 15.])\n",
      "M.sum(dim=1): tensor([15., 15., 15.])\n",
      "M.diag().sum(): tensor(15.)\n"
     ]
    }
   ],
   "source": [
    "# Magisches Quadrat \n",
    "M = torch.tensor([[4,9,2], [3,5,7], [8,1,6]], dtype=torch.float32)\n",
    "print('M:', M)\n",
    "print('M.sum():', M.sum())\n",
    "print('M.sum(dim=0):', M.sum(dim=0))\n",
    "print('M.sum(dim=1):', M.sum(dim=1))\n",
    "print('M.diag().sum():', M.diag().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: tensor([[1., 2., 3.],\n",
      "        [6., 5., 4.],\n",
      "        [7., 9., 8.]])\n",
      "M.argmax(): tensor(7)\n",
      "M.argmax(dim=0): tensor([2, 2, 2])\n",
      "M.argmax(dim=1): tensor([2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# Was ist argmax? Gibt den Index des größten Elements im Tensor zurück\n",
    "M = torch.tensor([[1,2,3], [6,5,4], [7,9,8]], dtype=torch.float32)\n",
    "print('M:', M)\n",
    "print('M.argmax():', M.argmax())\n",
    "print('M.argmax(dim=0):', M.argmax(dim=0))\n",
    "print('M.argmax(dim=1):', M.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Indexierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [6., 5., 4.],\n",
      "        [7., 9., 8.]])\n",
      "M[0,0]: tensor(1.)\n",
      "M[1,0]: tensor(6.)\n",
      "M[2,2]: tensor(8.)\n",
      "M[1, :]: tensor([6., 5., 4.])\n",
      "M[:, 1]: tensor([2., 5., 9.])\n"
     ]
    }
   ],
   "source": [
    "# Indexierung startet bei 0\n",
    "# M[0,0] -> 1. Zeile, 1. Spalte\n",
    "# M[1,0] -> 2. Zeile, 1. Spalte\n",
    "# M[2,2] -> 3. Zeile, 3. Spalte\n",
    "# : wird verwendet um alle Indices einer Dimension zu selektieren \n",
    "# M[1, :] -> 2. Zeile, alle Spalten\n",
    "# M[:, 1] -> alle Zeilen, 2. Spalte\n",
    "\n",
    "M = torch.tensor([[1,2,3], [6,5,4], [7,9,8]], dtype=torch.float32)\n",
    "print( M)\n",
    "print('M[0,0]:', M[0,0])\n",
    "print('M[1,0]:', M[1,0])\n",
    "print('M[2,2]:', M[2,2])\n",
    "print('M[1, :]:', M[1, :])\n",
    "print('M[:, 1]:', M[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "A[2:5]: tensor([3, 4, 5])\n",
      "A[:5]: tensor([1, 2, 3, 4, 5])\n",
      "A[5:]: tensor([ 6,  7,  8,  9, 10])\n",
      "A[-1]: tensor(10)\n",
      "A[-3:]: tensor([ 8,  9, 10])\n",
      "A[:-3]: tensor([1, 2, 3, 4, 5, 6, 7])\n",
      "\n",
      "tensor([[1., 2., 3.],\n",
      "        [6., 5., 4.],\n",
      "        [7., 9., 8.]])\n",
      "M[:, 0:2]: tensor([[1., 2.],\n",
      "        [6., 5.],\n",
      "        [7., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# Slicing, nutze  \"a:b\" um die Elemente von Index a bis b-1 zu selektieren\n",
    "A = torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "print(A)\n",
    "print('A[2:5]:', A[2:5])\n",
    "print('A[:5]:', A[:5])\n",
    "print('A[5:]:', A[5:])\n",
    "\n",
    "# Nutze - um von hinten zu zählen\n",
    "print('A[-1]:', A[-1])\n",
    "print('A[-3:]:', A[-3:])\n",
    "print('A[:-3]:', A[:-3], end='\\n\\n')\n",
    "\n",
    "# Analog für mehrdimensionale Tensoren ...\n",
    "print(M)\n",
    "print('M[:, 0:2]:', M[:, 0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([100,  90,  80,  70,  60,  50,  40,  30,  20,  10]),\n",
       " tensor([9, 8, 7, 6, 5, 4, 3, 2, 1, 0]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zur Vereinfachung wird folgendes Beispiel nur auf 1D Tensoren angewendet, ist aber auf mehrdimensionale Tensoren übertragbar\n",
    "A = torch.tensor([1,2,3,4,5,6,7,8,9,10]) *10\n",
    "sortiertes_A, sortierte_Indices = torch.sort(A, descending=True, )\n",
    "\n",
    "sortiertes_A, sortierte_Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([110,  99,  88,  77,  66,  55,  44,  33,  11,  22])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.tensor([2,1,3,4,5,6,7,8,9,10]) *11\n",
    "sortierte_Indices = torch.argsort(A, descending=True)\n",
    "nach_A_sortierte_B = B[sortierte_Indices]\n",
    "nach_A_sortierte_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False,  True,  True, False, False, False])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maskierung, \"Masking\"\n",
    "A = torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "mask = (A > 5) & (A < 8)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False, False, False, False,  True, False, False,  True, False, False]),\n",
       " tensor([ True,  True,  True,  True, False,  True,  True, False,  True,  True]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (A == 5) | (A == 8) \n",
    "mask, ~mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False, False,  True, False, False, False, False, False, False, False]),\n",
       " tensor([3]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mask = torch.zeros(10, dtype=torch.bool)\n",
    "my_mask[2] = True\n",
    "my_mask, A[my_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nutze sort(,...., dim=2) # Sortieren entlang der 2. Dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 View, Reshape, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 6., 5., 4., 7., 9., 8.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neben squeeze, unsqueeze gibt es auch flatten, view, reshape\n",
    "# M.argmax() \n",
    "M.flatten() # -> argmax dann definiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2025-03-02-18-01-43.png)\n",
    "https://stackoverflow.com/questions/42479902/what-does-view-do-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktioniert nur, wenn die dimensionen aufgehen:\n",
    "# nxm -> n*m Elemente\n",
    "# Wollen wir z.B. 3x4 -> 2x6, 6x2, 4x3, 12x1, 1x12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 82])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nutze -1, wenn du nicht weißt, wie viele Elemente in der Dimension sein sollen\n",
    "# Wollen in erster Dimension 2 Elemente haben\n",
    "T = torch.randn(246*3)\n",
    "T.view(9,-1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was macht .reshape? Genau das gleiche wie view, aber es kopiert die Daten immer (view schlägt fehl, wenn nicht contiguous), kommt gleich\n",
    "# Call by reference vs Call by value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation, Call by reference vs Call by value \n",
    ".contiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "# Pass by reference vs pass by value\n",
    "# torch cumsum, sum, mean, std, var, max, min, argmax, argmin\n",
    "# squeeze, unsqueeze, arange\n",
    "# masks\n",
    "# torch.mm, torch.where, torch.cat, torch.stack,torch.unique, torch.sort, torch.topk,torch.view, torch.transpose, torch.diag, torch.matrix_power\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
